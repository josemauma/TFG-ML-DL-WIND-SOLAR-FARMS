{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "Modelo_SP1 = load_model('Modelo_SP1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE_TIME              0\n",
      "SOURCE_KEY             0\n",
      "DC_POWER               0\n",
      "AC_POWER               0\n",
      "DAILY_YIELD            0\n",
      "TOTAL_YIELD            0\n",
      "AMBIENT_TEMPERATURE    4\n",
      "MODULE_TEMPERATURE     4\n",
      "IRRADIATION            4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos de generación y meteorológicos\n",
    "plant_1_generation = pd.read_csv('Plant_1_Generation_Data.csv')\n",
    "plant_1_weather = pd.read_csv('Plant_1_Weather_Sensor_Data.csv')\n",
    "\n",
    "# Copiar los datos de generación para mantener df_GD1 limpio\n",
    "df_GD1 = plant_1_generation.copy()\n",
    "\n",
    "# Aplicar el mapeo a los nombres de los paneles solares\n",
    "unique_source_keys_list = df_GD1['SOURCE_KEY'].unique()\n",
    "source_key_mapping = {key: f\"Solar_Panel_{i+1}\" for i, key in enumerate(unique_source_keys_list)}\n",
    "df_GD1['SOURCE_KEY'] = df_GD1['SOURCE_KEY'].map(source_key_mapping)\n",
    "\n",
    "# Convertir la columna 'DATE_TIME' a formato de fecha y hora\n",
    "df_GD1['DATE_TIME'] = pd.to_datetime(df_GD1['DATE_TIME'], format='%d-%m-%Y %H:%M')\n",
    "plant_1_weather['DATE_TIME'] = pd.to_datetime(plant_1_weather['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Unir los datos meteorológicos al dataframe de generación en función de la fecha y hora\n",
    "df_GD1_with_weather = pd.merge(df_GD1, plant_1_weather, on='DATE_TIME', how='left')\n",
    "\n",
    "# Eliminar las columnas PLANT_ID_y y SOURCE_KEY_y y renombrar las columnas PLANT_ID_x y SOURCE_KEY_x\n",
    "df_GD1_with_weather_clean = df_GD1_with_weather.drop(columns=['PLANT_ID_y', 'SOURCE_KEY_y','PLANT_ID_x'])\n",
    "\n",
    "# Renombrar las columnas para eliminar el sufijo '_x'\n",
    "df_GD1_with_weather_clean = df_GD1_with_weather_clean.rename(columns={'SOURCE_KEY_x': 'SOURCE_KEY'})\n",
    "\n",
    "nulos = df_GD1_with_weather_clean.isnull().sum()\n",
    "\n",
    "# Mostrar cuántos valores nulos hay por columna\n",
    "print(nulos)\n",
    "\n",
    "# Rellenar los valores nulos en solo las columnas numéricas con la media\n",
    "numerical_cols = df_GD1_with_weather_clean.select_dtypes(include=['float64', 'int64']).columns #Estp para quitar los floats\n",
    "df_GD1_with_weather_clean[numerical_cols] = df_GD1_with_weather_clean[numerical_cols].fillna(df_GD1_with_weather_clean[numerical_cols].mean())\n",
    "\n",
    "df_GD1_limpio = df_GD1_with_weather_clean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en cada columna (planta 2):\n",
      " DATE_TIME              0\n",
      "SOURCE_KEY             0\n",
      "DC_POWER               0\n",
      "AC_POWER               0\n",
      "DAILY_YIELD            0\n",
      "TOTAL_YIELD            0\n",
      "AMBIENT_TEMPERATURE    0\n",
      "MODULE_TEMPERATURE     0\n",
      "IRRADIATION            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos de generación y meteorológicos para la planta 2\n",
    "plant_2_generation = pd.read_csv('Plant_2_Generation_Data.csv')\n",
    "plant_2_weather = pd.read_csv('Plant_2_Weather_Sensor_Data.csv')\n",
    "\n",
    "# Copiar los datos de generación para mantener df_GD2 limpio\n",
    "df_GD2 = plant_2_generation.copy()\n",
    "\n",
    "# Aplicar el mapeo a los nombres de los paneles solares\n",
    "unique_source_keys_list_2 = df_GD2['SOURCE_KEY'].unique()\n",
    "source_key_mapping_2 = {key: f\"Solar_Panel_{i+1}\" for i, key in enumerate(unique_source_keys_list_2)}\n",
    "df_GD2['SOURCE_KEY'] = df_GD2['SOURCE_KEY'].map(source_key_mapping_2)\n",
    "\n",
    "# Convertir la columna 'DATE_TIME' a formato de fecha y hora\n",
    "# Ajustar el formato de fecha según sea necesario para que coincida con el archivo de la planta 2\n",
    "df_GD2['DATE_TIME'] = pd.to_datetime(df_GD2['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "plant_2_weather['DATE_TIME'] = pd.to_datetime(plant_2_weather['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Unir los datos meteorológicos al dataframe de generación en función de la fecha y hora\n",
    "df_GD2_with_weather = pd.merge(df_GD2, plant_2_weather, on='DATE_TIME', how='left')\n",
    "\n",
    "# Eliminar las columnas PLANT_ID_y y SOURCE_KEY_y y renombrar las columnas PLANT_ID_x y SOURCE_KEY_x\n",
    "df_GD2_with_weather_clean = df_GD2_with_weather.drop(columns=['PLANT_ID_y', 'SOURCE_KEY_y', 'PLANT_ID_x'])\n",
    "\n",
    "# Renombrar las columnas para eliminar el sufijo '_x'\n",
    "df_GD2_with_weather_clean = df_GD2_with_weather_clean.rename(columns={'SOURCE_KEY_x': 'SOURCE_KEY'})\n",
    "\n",
    "# Mostrar cuántos valores nulos hay por columna\n",
    "nulos2 = df_GD2_with_weather_clean.isnull().sum()\n",
    "print(\"Valores nulos en cada columna (planta 2):\\n\", nulos2)\n",
    "\n",
    "# Rellenar los valores nulos en solo las columnas numéricas con la media\n",
    "numerical_cols_2 = df_GD2_with_weather_clean.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_GD2_with_weather_clean[numerical_cols_2] = df_GD2_with_weather_clean[numerical_cols_2].fillna(df_GD2_with_weather_clean[numerical_cols_2].mean())\n",
    "\n",
    "# Guardar el dataframe limpio de la planta 2\n",
    "df_GD2_limpio = df_GD2_with_weather_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD', 'AMBIENT_TEMPERATURE', \n",
    "            'MODULE_TEMPERATURE', 'IRRADIATION']\n",
    "X_ker_plant2 = df_GD2_limpio[features].values\n",
    "Y_ker_plant2 = df_GD2_limpio['DC_POWER'].values  # Definir la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Cargar el escalador guardado\n",
    "scaler_ker = joblib.load('scaler_ker.pkl')\n",
    "X_ker_plant2_scaled = scaler_ker.transform(X_ker_plant2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2116/2116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step\n",
      "Resultados en los datos de plant_2:\n",
      "MSE: 5984739418.895538\n",
      "MAE: 52798.53770752772\n",
      "R²: -43581.495198547294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# Realizar predicciones en los datos de plant_2\n",
    "Y_pred_plant2 = Modelo_SP1.predict(X_ker_plant2_scaled)\n",
    "\n",
    "# Calcular métricas de rendimiento\n",
    "mse_plant2 = mean_squared_error(Y_ker_plant2, Y_pred_plant2)\n",
    "mae_plant2 = mean_absolute_error(Y_ker_plant2, Y_pred_plant2)\n",
    "r2_plant2 = r2_score(Y_ker_plant2, Y_pred_plant2)\n",
    "\n",
    "print(\"Resultados en los datos de plant_2:\")\n",
    "print(\"MSE:\", mse_plant2)\n",
    "print(\"MAE:\", mae_plant2)\n",
    "print(\"R²:\", r2_plant2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
