{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE_TIME              0\n",
      "SOURCE_KEY             0\n",
      "DC_POWER               0\n",
      "AC_POWER               0\n",
      "DAILY_YIELD            0\n",
      "TOTAL_YIELD            0\n",
      "AMBIENT_TEMPERATURE    4\n",
      "MODULE_TEMPERATURE     4\n",
      "IRRADIATION            4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos de generación y meteorológicos\n",
    "plant_1_generation = pd.read_csv('Plant_1_Generation_Data.csv')\n",
    "plant_1_weather = pd.read_csv('Plant_1_Weather_Sensor_Data.csv')\n",
    "\n",
    "# Copiar los datos de generación para mantener df_GD1 limpio\n",
    "df_GD1 = plant_1_generation.copy()\n",
    "\n",
    "# Aplicar el mapeo a los nombres de los paneles solares\n",
    "unique_source_keys_list = df_GD1['SOURCE_KEY'].unique()\n",
    "source_key_mapping = {key: f\"Solar_Panel_{i+1}\" for i, key in enumerate(unique_source_keys_list)}\n",
    "df_GD1['SOURCE_KEY'] = df_GD1['SOURCE_KEY'].map(source_key_mapping)\n",
    "\n",
    "# Convertir la columna 'DATE_TIME' a formato de fecha y hora\n",
    "df_GD1['DATE_TIME'] = pd.to_datetime(df_GD1['DATE_TIME'], format='%d-%m-%Y %H:%M')\n",
    "plant_1_weather['DATE_TIME'] = pd.to_datetime(plant_1_weather['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Unir los datos meteorológicos al dataframe de generación en función de la fecha y hora\n",
    "df_GD1_with_weather = pd.merge(df_GD1, plant_1_weather, on='DATE_TIME', how='left')\n",
    "\n",
    "# Eliminar las columnas PLANT_ID_y y SOURCE_KEY_y y renombrar las columnas PLANT_ID_x y SOURCE_KEY_x\n",
    "df_GD1_with_weather_clean = df_GD1_with_weather.drop(columns=['PLANT_ID_y', 'SOURCE_KEY_y','PLANT_ID_x'])\n",
    "\n",
    "# Renombrar las columnas para eliminar el sufijo '_x'\n",
    "df_GD1_with_weather_clean = df_GD1_with_weather_clean.rename(columns={'SOURCE_KEY_x': 'SOURCE_KEY'})\n",
    "\n",
    "nulos = df_GD1_with_weather_clean.isnull().sum()\n",
    "\n",
    "# Mostrar cuántos valores nulos hay por columna\n",
    "print(nulos)\n",
    "\n",
    "# Rellenar los valores nulos en solo las columnas numéricas con la media\n",
    "numerical_cols = df_GD1_with_weather_clean.select_dtypes(include=['float64', 'int64']).columns #Estp para quitar los floats\n",
    "df_GD1_with_weather_clean[numerical_cols] = df_GD1_with_weather_clean[numerical_cols].fillna(df_GD1_with_weather_clean[numerical_cols].mean())\n",
    "\n",
    "df_GD1_limpio = df_GD1_with_weather_clean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en cada columna (planta 2):\n",
      " DATE_TIME              0\n",
      "SOURCE_KEY             0\n",
      "DC_POWER               0\n",
      "AC_POWER               0\n",
      "DAILY_YIELD            0\n",
      "TOTAL_YIELD            0\n",
      "AMBIENT_TEMPERATURE    0\n",
      "MODULE_TEMPERATURE     0\n",
      "IRRADIATION            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos de generación y meteorológicos para la planta 2\n",
    "plant_2_generation = pd.read_csv('Plant_2_Generation_Data.csv')\n",
    "plant_2_weather = pd.read_csv('Plant_2_Weather_Sensor_Data.csv')\n",
    "\n",
    "# Copiar los datos de generación para mantener df_GD2 limpio\n",
    "df_GD2 = plant_2_generation.copy()\n",
    "\n",
    "# Aplicar el mapeo a los nombres de los paneles solares\n",
    "unique_source_keys_list_2 = df_GD2['SOURCE_KEY'].unique()\n",
    "source_key_mapping_2 = {key: f\"Solar_Panel_{i+1}\" for i, key in enumerate(unique_source_keys_list_2)}\n",
    "df_GD2['SOURCE_KEY'] = df_GD2['SOURCE_KEY'].map(source_key_mapping_2)\n",
    "\n",
    "# Convertir la columna 'DATE_TIME' a formato de fecha y hora\n",
    "# Ajustar el formato de fecha según sea necesario para que coincida con el archivo de la planta 2\n",
    "df_GD2['DATE_TIME'] = pd.to_datetime(df_GD2['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "plant_2_weather['DATE_TIME'] = pd.to_datetime(plant_2_weather['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Unir los datos meteorológicos al dataframe de generación en función de la fecha y hora\n",
    "df_GD2_with_weather = pd.merge(df_GD2, plant_2_weather, on='DATE_TIME', how='left')\n",
    "\n",
    "# Eliminar las columnas PLANT_ID_y y SOURCE_KEY_y y renombrar las columnas PLANT_ID_x y SOURCE_KEY_x\n",
    "df_GD2_with_weather_clean = df_GD2_with_weather.drop(columns=['PLANT_ID_y', 'SOURCE_KEY_y', 'PLANT_ID_x'])\n",
    "\n",
    "# Renombrar las columnas para eliminar el sufijo '_x'\n",
    "df_GD2_with_weather_clean = df_GD2_with_weather_clean.rename(columns={'SOURCE_KEY_x': 'SOURCE_KEY'})\n",
    "\n",
    "# Mostrar cuántos valores nulos hay por columna\n",
    "nulos2 = df_GD2_with_weather_clean.isnull().sum()\n",
    "print(\"Valores nulos en cada columna (planta 2):\\n\", nulos2)\n",
    "\n",
    "# Rellenar los valores nulos en solo las columnas numéricas con la media\n",
    "numerical_cols_2 = df_GD2_with_weather_clean.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_GD2_with_weather_clean[numerical_cols_2] = df_GD2_with_weather_clean[numerical_cols_2].fillna(df_GD2_with_weather_clean[numerical_cols_2].mean())\n",
    "\n",
    "# Guardar el dataframe limpio de la planta 2\n",
    "df_GD2_limpio = df_GD2_with_weather_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "#import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en cada fold: [393500.28125, 328139.15625, 477386.84375, 34528.0546875, 94843.7734375]\n",
      "MSE promedio en validación cruzada: 265679.621875\n",
      "MAE en cada fold: [206.253173828125, 145.23312377929688, 211.56549072265625, 70.1822509765625, 72.34170532226562]\n",
      "MAE promedio en validación cruzada: 141.11514892578126\n",
      "R² en cada fold: [0.9627260977487576, 0.9686569830430797, 0.9541084021956147, 0.996915614201675, 0.9912225146440907]\n",
      "R² promedio en validación cruzada: 0.9747259223666435\n"
     ]
    }
   ],
   "source": [
    "df_combined = pd.concat([df_GD1_limpio, df_GD2_limpio], ignore_index=True)\n",
    "\n",
    "# Definir las características (X) y la variable objetivo (Y)\n",
    "features = ['AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD', 'AMBIENT_TEMPERATURE', \n",
    "            'MODULE_TEMPERATURE', 'IRRADIATION']\n",
    "X_combined = df_combined[features].values\n",
    "Y_combined = df_combined['DC_POWER'].values\n",
    "\n",
    "# Configuración de la validación cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# Entrenar y evaluar en cada fold\n",
    "for train_index, test_index in kf.split(X_combined):\n",
    "    X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
    "    Y_train, Y_test = Y_combined[train_index], Y_combined[test_index]\n",
    "    \n",
    "    # Escalar los datos de entrenamiento y prueba\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    #joblib.dump(scaler, 'scaler_ker2.pkl')\n",
    "    \n",
    "    # Definir el modelo con la estructura dada\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.05)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.05)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.05)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])\n",
    "    \n",
    "    # Definir early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(X_train, Y_train, epochs=100, batch_size=32, verbose=0,\n",
    "                        validation_data=(X_test, Y_test), callbacks=[early_stop])\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    mse, mae = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    # Calcular R² en el conjunto de prueba\n",
    "    Y_test_pred = model.predict(X_test, verbose=0)\n",
    "    r2 = r2_score(Y_test, Y_test_pred)\n",
    "    r2_scores.append(r2)\n",
    "  \n",
    "# Resultados promedio\n",
    "print(\"MSE en cada fold:\", mse_scores)\n",
    "print(\"MSE promedio en validación cruzada:\", np.mean(mse_scores))\n",
    "print(\"MAE en cada fold:\", mae_scores)\n",
    "print(\"MAE promedio en validación cruzada:\", np.mean(mae_scores))\n",
    "print(\"R² en cada fold:\", r2_scores)\n",
    "print(\"R² promedio en validación cruzada:\", np.mean(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE en cada fold: [45823.6875, 358414.40625, 169165.640625, 135794.765625, 375124.09375]\n",
    "\n",
    "MSE promedio en validación cruzada: 216864.51875\n",
    "\n",
    "MAE en cada fold: [77.87956237792969, 157.6117401123047, 106.89422607421875, 107.74468994140625, 177.47055053710938]\n",
    "\n",
    "MAE promedio en validación cruzada: 125.52015380859375\n",
    "\n",
    "R² en cada fold:    [0.9959622648074015, 0.9657029025445529, 0.9839423221699306, 0.9869721278591586, 0.9641352531321542]\n",
    "\n",
    "R² promedio en validación cruzada: 0.9793429741026396"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
